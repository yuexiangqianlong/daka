[2018-01-07T16:05:59,331][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"D:/www/sdk/dakaKoa2/logstash-6.1.1/modules/fb_apache/configuration"}
[2018-01-07T16:05:59,364][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"D:/www/sdk/dakaKoa2/logstash-6.1.1/modules/netflow/configuration"}
[2018-01-07T16:05:59,665][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-01-07T16:06:00,495][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.1.1"}
[2018-01-07T16:06:01,825][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-01-07T16:06:10,321][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//127.0.0.1:9200], index=>"pserson", document_type=>"score", document_id=>"%{id}", id=>"d27b06b398a2ed9e1b77c7e21b9f2a9f12415a52925baecf075c9c6cdc94017c", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_0275c760-1394-4684-9e89-3e2ddd97d107", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-01-07T16:06:12,851][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2018-01-07T16:06:12,871][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T16:06:14,051][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2018-01-07T16:06:14,111][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>nil}
[2018-01-07T16:06:14,121][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-01-07T16:06:14,141][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-01-07T16:06:14,251][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-01-07T16:06:14,361][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1:9200"]}
[2018-01-07T16:06:14,391][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500, :thread=>"#<Thread:0x1e508852 run>"}
[2018-01-07T16:06:18,081][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2018-01-07T16:06:18,541][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-01-07T16:07:08,818][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT version()
[2018-01-07T16:07:09,398][INFO ][logstash.inputs.jdbc     ] (0.360000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:07:09,458][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:08:09,826][INFO ][logstash.inputs.jdbc     ] (0.018000s) SELECT version()
[2018-01-07T16:08:10,107][INFO ][logstash.inputs.jdbc     ] (0.032000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:08:10,299][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:09:00,474][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:09:00,914][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:09:01,146][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:10:00,749][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:10:00,920][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:10:01,320][INFO ][logstash.inputs.jdbc     ] (0.160000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:11:00,813][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:11:00,843][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:11:00,868][INFO ][logstash.inputs.jdbc     ] (0.002000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:12:01,251][INFO ][logstash.inputs.jdbc     ] (0.140000s) SELECT version()
[2018-01-07T16:12:01,411][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:12:01,421][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:13:36,659][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:13:37,919][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:13:38,229][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:15:32,036][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:15:32,706][INFO ][logstash.inputs.jdbc     ] (0.150000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:15:32,926][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:16:00,706][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:16:00,836][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:16:01,126][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:16:00,366][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2018-01-07T16:16:02,906][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T16:16:02,906][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T16:16:02,906][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T16:16:03,066][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T16:16:04,236][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2018-01-07T16:16:04,366][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>2}
[2018-01-07T16:16:04,366][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Unrecognized Windows Sockets error: 0: recv failed", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2018-01-07T16:16:04,366][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>2}
[2018-01-07T16:16:04,376][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>2}
[2018-01-07T16:17:00,535][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:17:00,585][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:17:00,705][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:18:00,686][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:18:00,726][INFO ][logstash.inputs.jdbc     ] (0.009000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:18:00,807][INFO ][logstash.inputs.jdbc     ] (0.020000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:19:00,582][INFO ][logstash.inputs.jdbc     ] (0.060000s) SELECT version()
[2018-01-07T16:19:00,862][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:19:00,872][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:20:00,238][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:20:00,248][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:20:00,248][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:21:04,351][INFO ][logstash.inputs.jdbc     ] (0.020000s) SELECT version()
[2018-01-07T16:21:04,631][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:21:04,731][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:22:00,991][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:22:01,021][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:22:01,111][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:23:01,070][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:23:01,200][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:23:01,240][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:24:00,555][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:24:00,615][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:24:00,645][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:25:04,357][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:25:04,520][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:25:05,139][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:26:00,509][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT version()
[2018-01-07T16:26:00,519][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:26:00,520][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:27:00,699][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:27:01,419][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:27:01,419][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:28:00,864][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:28:00,984][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:28:00,994][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:29:03,535][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:29:06,939][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:29:06,949][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:30:08,514][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT version()
[2018-01-07T16:30:10,909][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:30:10,994][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:31:00,273][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:31:00,314][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:31:00,314][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:32:00,315][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:32:00,325][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:32:00,325][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:33:00,322][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:33:00,322][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:33:00,362][INFO ][logstash.inputs.jdbc     ] (0.030000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:34:00,371][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:34:00,431][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:34:00,431][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:35:00,467][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:35:00,477][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:35:00,477][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:36:00,128][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:36:00,148][INFO ][logstash.inputs.jdbc     ] (0.020000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:36:00,158][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:37:00,410][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:37:00,420][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:37:00,430][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:38:00,327][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:38:00,377][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:38:00,407][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:39:00,884][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:39:00,964][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:39:00,984][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:40:00,393][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:40:00,473][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:40:00,483][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:41:00,234][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:41:00,234][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:41:00,264][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:42:00,103][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT version()
[2018-01-07T16:42:00,123][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:42:00,133][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:43:00,794][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:43:01,304][INFO ][logstash.inputs.jdbc     ] (0.480000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:43:01,334][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:44:00,200][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:44:00,230][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:44:00,270][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:45:00,258][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:45:00,288][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:45:00,318][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:46:00,515][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:46:00,585][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:46:00,625][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:47:00,101][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:47:00,131][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:47:00,171][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:48:00,174][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:48:00,214][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:48:00,244][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:49:00,071][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:49:00,111][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:49:00,141][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:50:00,314][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:50:00,354][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:50:00,384][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:51:00,912][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:51:00,942][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:51:00,982][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:52:15,084][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:52:15,934][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:52:16,174][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:53:00,603][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:53:00,723][INFO ][logstash.inputs.jdbc     ] (0.070000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:53:00,843][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:54:00,331][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:54:00,371][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:54:00,401][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:55:00,499][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:55:00,529][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:55:00,559][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:56:00,495][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:56:00,585][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:56:00,625][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:57:00,212][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:57:00,242][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:57:00,282][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:58:02,645][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:58:03,125][INFO ][logstash.inputs.jdbc     ] (0.200000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:58:03,255][INFO ][logstash.inputs.jdbc     ] (0.090000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T16:59:01,408][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T16:59:01,958][INFO ][logstash.inputs.jdbc     ] (0.380000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T16:59:02,238][INFO ][logstash.inputs.jdbc     ] (0.250000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:00:00,345][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:00:00,385][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:00:00,495][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:01:00,224][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:01:00,264][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:01:00,334][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:02:00,212][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:02:00,272][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:02:00,312][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:03:40,431][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:03:41,271][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:03:41,301][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:04:00,173][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:04:00,202][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:04:00,233][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:05:00,341][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:05:00,371][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:05:00,401][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:06:01,601][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:06:02,181][INFO ][logstash.inputs.jdbc     ] (0.550000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:06:02,361][INFO ][logstash.inputs.jdbc     ] (0.140000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:07:00,835][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:07:00,975][INFO ][logstash.inputs.jdbc     ] (0.100000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:07:01,085][INFO ][logstash.inputs.jdbc     ] (0.070000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:08:00,774][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:08:00,924][INFO ][logstash.inputs.jdbc     ] (0.120000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:08:01,014][INFO ][logstash.inputs.jdbc     ] (0.060000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:09:03,566][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:09:05,066][INFO ][logstash.inputs.jdbc     ] (1.460000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:09:08,176][INFO ][logstash.inputs.jdbc     ] (3.080000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:10:00,452][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:10:00,652][INFO ][logstash.inputs.jdbc     ] (0.170000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:10:00,762][INFO ][logstash.inputs.jdbc     ] (0.080000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:11:00,271][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:11:00,481][INFO ][logstash.inputs.jdbc     ] (0.170000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:11:00,721][INFO ][logstash.inputs.jdbc     ] (0.210000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:12:00,269][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:12:00,299][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:12:00,339][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:13:00,120][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:13:00,150][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:13:00,320][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:14:00,354][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:14:00,384][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:14:00,424][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:15:00,131][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:15:00,161][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:15:00,191][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:16:00,341][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:16:00,381][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:16:00,411][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:17:00,197][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:17:00,227][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:17:00,257][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:18:00,844][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:18:00,874][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:18:00,904][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:19:00,290][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:19:00,330][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:19:00,370][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:20:00,220][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:20:00,250][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:20:00,290][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:21:00,302][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:21:00,342][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:21:00,372][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:22:00,285][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:22:00,325][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:22:00,355][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:23:00,111][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:23:00,141][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:23:00,181][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:24:00,138][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:24:00,168][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:24:00,198][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:25:00,173][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT version()
[2018-01-07T17:25:00,208][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:25:00,241][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:26:00,201][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:26:00,236][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:26:00,269][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:27:00,102][INFO ][logstash.inputs.jdbc     ] (0.002000s) SELECT version()
[2018-01-07T17:27:00,135][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:27:00,209][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:28:00,182][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:28:00,212][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:28:00,242][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:29:00,019][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT version()
[2018-01-07T17:29:00,052][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:29:00,083][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:30:00,161][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:30:00,201][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:30:00,231][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:31:00,263][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:31:00,303][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:31:00,333][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:32:00,456][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT version()
[2018-01-07T17:32:00,528][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:32:00,563][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:33:00,153][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:33:00,183][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:33:00,223][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:34:00,176][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:34:00,210][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:34:00,243][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:35:00,259][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:35:00,289][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:35:00,319][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:36:00,147][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:36:00,187][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:36:00,217][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:37:00,130][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:37:00,180][INFO ][logstash.inputs.jdbc     ] (0.020000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:37:00,220][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:38:00,181][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:38:00,221][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:38:00,251][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:39:00,053][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:39:00,083][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:39:00,203][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:40:00,114][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:40:00,154][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:40:00,184][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:41:00,298][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:41:00,328][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:41:00,358][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:42:00,322][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:42:00,352][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:42:00,382][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:43:00,239][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:43:00,279][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:43:00,309][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:44:00,230][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:44:00,270][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:44:00,300][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:45:00,309][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:45:00,339][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:45:00,369][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:46:00,210][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:46:00,240][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:46:00,270][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:47:00,109][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:47:00,139][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:47:00,169][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:48:00,063][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:48:00,103][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:48:00,133][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:49:00,305][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:49:00,345][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:49:00,385][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:50:01,656][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:50:01,686][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:50:01,726][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:51:00,396][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:51:00,426][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:51:00,456][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:52:00,352][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:52:00,382][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:52:00,412][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:53:00,336][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:53:00,371][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:53:00,403][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:54:00,103][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:54:00,133][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:54:00,213][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:55:00,066][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:55:00,098][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:55:00,130][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:56:00,023][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:56:00,063][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:56:00,093][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:57:00,114][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:57:00,164][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:57:00,204][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:58:00,435][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:58:00,465][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:58:00,495][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T17:59:00,237][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T17:59:00,271][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T17:59:00,303][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:00:00,337][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:00:00,377][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:00:00,407][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:01:00,180][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:01:00,210][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:01:00,240][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:02:00,306][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:02:00,346][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:02:00,376][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:03:00,298][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:03:00,328][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:03:00,358][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:04:00,118][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:04:00,188][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:04:00,218][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:05:00,431][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT version()
[2018-01-07T18:05:00,461][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:05:00,501][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:06:00,361][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:06:00,391][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:06:00,421][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:07:00,252][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:07:00,313][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:07:00,342][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:08:00,098][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:08:00,128][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:08:00,158][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:09:00,227][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:09:00,267][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:09:00,487][INFO ][logstash.inputs.jdbc     ] (0.190000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:10:00,120][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:10:00,154][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:10:00,188][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:11:00,062][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:11:00,092][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:11:00,132][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:12:00,174][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:12:00,214][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:12:00,244][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:13:00,265][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:13:00,293][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:13:00,323][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:14:00,190][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:14:00,220][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:14:00,250][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:15:00,421][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:15:00,461][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:15:00,491][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:16:00,283][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:16:00,333][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:16:00,373][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:17:00,242][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:17:00,282][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:17:00,312][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:18:00,286][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:18:00,336][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:18:00,383][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:19:00,137][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:19:00,167][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:19:00,208][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:20:00,417][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:20:00,447][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:20:00,477][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:21:00,475][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:21:00,505][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:21:00,535][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:22:00,114][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:22:00,144][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:22:00,184][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:23:00,343][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:23:00,383][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:23:00,413][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:24:00,209][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:24:00,239][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:24:00,269][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:25:00,403][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:25:00,445][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:25:00,469][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:26:00,191][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:26:00,221][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:26:00,251][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:27:00,155][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:27:00,195][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:27:00,225][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:28:00,369][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:28:00,399][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:28:00,429][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:29:00,316][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:29:00,346][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:29:00,376][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:30:00,516][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:30:00,556][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:30:00,596][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:31:00,324][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:31:00,354][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:31:00,394][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:32:00,337][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:32:00,377][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:32:00,407][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:33:00,434][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:33:00,468][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:33:00,498][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:34:00,320][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:34:00,350][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:34:00,390][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:35:00,040][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:35:00,080][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:35:00,110][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:36:00,321][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:36:00,351][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:36:00,391][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:37:00,373][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:37:00,403][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:37:00,433][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:38:00,372][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:38:00,402][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:38:00,432][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:39:00,433][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:39:00,463][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:39:00,494][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:40:00,244][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:40:00,274][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:40:00,304][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:41:00,147][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:41:00,177][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:41:00,217][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:42:00,331][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:42:00,361][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:42:00,391][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:43:00,357][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:43:00,387][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:43:00,427][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:44:00,307][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT version()
[2018-01-07T18:44:00,337][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:44:00,367][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:45:00,233][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:45:00,273][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:45:00,303][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:46:00,169][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:46:00,199][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:46:00,229][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:47:00,410][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:47:00,440][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:47:00,470][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:48:00,230][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:48:00,270][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:48:00,300][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:49:00,162][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:49:00,192][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:49:00,222][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:50:00,422][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:50:00,462][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:50:00,492][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:51:00,263][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:51:00,303][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:51:00,333][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:52:00,292][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:52:00,322][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:52:00,362][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:53:00,222][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:53:00,252][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:53:00,322][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:54:00,188][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:54:00,228][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:54:00,258][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:55:00,313][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:55:00,353][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:55:00,393][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:56:00,405][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:56:00,435][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:56:00,465][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:57:00,196][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:57:00,226][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:57:00,256][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:58:00,526][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:58:00,606][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:58:00,646][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T18:59:00,246][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T18:59:00,276][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T18:59:00,306][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:00:00,297][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:00:00,337][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:00:00,367][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:01:00,187][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:01:00,217][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:01:00,247][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:02:00,418][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:02:00,458][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:02:00,488][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:03:00,269][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:03:00,299][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:03:00,329][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:04:00,210][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:04:00,240][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:04:00,280][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:05:00,344][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:05:00,374][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:05:00,404][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:06:00,382][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:06:00,422][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:06:00,452][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:07:00,174][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT version()
[2018-01-07T19:07:00,204][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:07:00,244][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:08:00,519][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:08:00,559][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:08:00,609][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:09:00,267][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:09:00,297][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:09:00,347][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:10:00,159][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:10:00,189][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:10:00,219][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:11:00,110][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:11:00,140][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:11:00,180][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:12:00,332][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:12:00,362][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:12:00,422][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:13:00,249][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:13:00,303][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:13:00,335][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:14:00,284][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:14:00,324][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:14:00,354][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:15:00,101][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:15:00,141][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:15:00,171][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:16:00,212][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:16:00,252][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:16:00,282][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:17:00,356][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:17:00,386][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:17:00,416][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:18:00,183][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:18:00,223][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:18:00,253][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:19:00,231][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:19:00,261][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:19:00,664][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:20:00,157][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:20:00,277][INFO ][logstash.inputs.jdbc     ] (0.090000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:20:00,317][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:21:00,040][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:21:00,070][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:21:00,100][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:22:00,252][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:22:00,282][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:22:00,312][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:23:00,133][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:23:00,163][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:23:00,193][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:24:00,299][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:24:00,329][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:24:00,359][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:25:00,059][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:25:00,089][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:25:00,119][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:26:00,253][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:26:00,283][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:26:00,323][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:27:00,105][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:27:00,145][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:27:00,185][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:28:00,060][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT version()
[2018-01-07T19:28:00,095][INFO ][logstash.inputs.jdbc     ] (0.002000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:28:00,128][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:29:00,148][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:29:00,178][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:29:00,218][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:30:00,159][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:30:00,189][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:30:00,229][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:31:00,231][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:31:00,265][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:31:00,297][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:32:00,063][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:32:00,093][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:32:00,123][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:33:00,157][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:33:00,312][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:33:00,342][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:34:00,304][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:34:00,344][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:34:00,374][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:35:00,218][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:35:00,254][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:35:00,303][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:36:00,237][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT version()
[2018-01-07T19:36:00,280][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:36:00,321][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:37:00,104][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:37:00,144][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:37:00,174][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:38:00,198][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:38:00,236][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:38:00,277][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:39:00,326][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT version()
[2018-01-07T19:39:00,356][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:39:00,386][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:40:00,251][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:40:00,281][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:40:00,311][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:41:00,395][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT version()
[2018-01-07T19:41:00,429][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:41:00,465][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:42:00,052][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:42:00,082][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:42:00,112][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:42:04,216][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2018-01-07T19:42:04,416][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2018-01-07T19:42:04,446][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2018-01-07T19:42:04,476][WARN ][logstash.outputs.elasticsearch] Marking url as dead. Last error: [LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError] Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect {:url=>http://127.0.0.1:9200/, :error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect", :error_class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError"}
[2018-01-07T19:42:04,846][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2018-01-07T19:42:04,846][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2018-01-07T19:42:04,846][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2018-01-07T19:42:04,846][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch' but Elasticsearch appears to be unreachable or down! {:error_message=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError", :will_retry_in_seconds=>2}
[2018-01-07T19:42:07,638][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:07,638][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:07,668][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2018-01-07T19:42:07,698][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2018-01-07T19:42:07,828][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:07,828][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:07,888][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2018-01-07T19:42:07,858][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:42:07,888][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>4}
[2018-01-07T19:42:10,339][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:42:11,729][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:11,749][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:11,769][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>8}
[2018-01-07T19:42:11,799][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>8}
[2018-01-07T19:42:11,919][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:11,939][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>8}
[2018-01-07T19:42:11,969][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:11,999][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>8}
[2018-01-07T19:42:13,499][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:42:14,529][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:42:18,563][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:42:19,593][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:42:19,833][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:19,853][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>16}
[2018-01-07T19:42:19,863][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:19,913][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>16}
[2018-01-07T19:42:19,973][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:19,993][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>16}
[2018-01-07T19:42:20,033][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:20,053][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>16}
[2018-01-07T19:42:23,648][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:42:24,691][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:42:28,744][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:42:29,824][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:42:33,904][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:42:34,954][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:42:35,887][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:35,917][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>32}
[2018-01-07T19:42:35,947][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:35,977][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>32}
[2018-01-07T19:42:36,027][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:36,067][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>32}
[2018-01-07T19:42:36,147][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:42:36,187][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>32}
[2018-01-07T19:42:38,988][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:42:40,028][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:42:44,075][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:42:45,105][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:42:49,144][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:42:50,176][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:42:54,216][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:42:55,252][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:42:59,283][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:43:00,692][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:43:01,041][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:43:01,075][INFO ][logstash.inputs.jdbc     ] (0.001000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:43:01,483][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:43:04,531][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:43:05,637][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:43:07,956][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:43:08,017][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:43:08,034][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>64}
[2018-01-07T19:43:08,050][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>64}
[2018-01-07T19:43:08,157][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:43:08,192][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>64}
[2018-01-07T19:43:08,219][WARN ][logstash.outputs.elasticsearch] UNEXPECTED POOL ERROR {:e=>#<LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError: No Available connections>}
[2018-01-07T19:43:08,252][ERROR][logstash.outputs.elasticsearch] Attempted to send a bulk request to elasticsearch, but no there are no living connections in the connection pool. Perhaps Elasticsearch is unreachable or down? {:error_message=>"No Available connections", :class=>"LogStash::Outputs::ElasticSearch::HttpClient::Pool::NoConnectionAvailableError", :will_retry_in_seconds=>64}
[2018-01-07T19:43:09,692][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:43:10,863][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:43:14,895][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:43:15,977][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:43:20,009][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:43:21,128][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:43:25,162][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:43:26,230][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:43:30,267][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:43:31,325][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:43:35,365][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:43:36,398][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:43:40,454][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:43:41,484][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=>"http://127.0.0.1:9200/", :error_type=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=>"Elasticsearch Unreachable: [http://127.0.0.1:9200/][Manticore::SocketException] Connection refused: connect"}
[2018-01-07T19:43:45,535][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T19:43:47,155][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2018-01-07T19:44:00,261][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:44:00,301][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:44:00,331][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:45:00,376][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:45:00,406][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:45:00,436][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:46:00,485][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:46:00,525][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:46:00,555][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:47:00,392][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:47:00,442][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:47:00,482][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:48:00,303][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:48:00,343][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:48:00,373][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:49:00,138][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:49:00,208][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:49:00,318][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:50:00,101][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:50:00,131][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:50:00,161][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:51:00,293][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:51:00,333][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:51:00,363][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:52:00,302][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:52:00,342][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:52:00,372][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:53:00,295][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:53:00,325][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:53:00,400][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:54:00,340][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:54:00,380][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:54:00,410][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:55:00,350][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:55:00,390][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:55:00,420][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:56:00,209][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:56:00,259][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:56:00,289][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:57:00,291][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:57:00,321][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:57:00,351][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:58:00,189][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:58:00,219][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:58:00,249][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T19:59:00,181][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T19:59:00,221][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T19:59:00,251][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T20:00:00,422][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T20:00:00,462][INFO ][logstash.inputs.jdbc     ] (0.010000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T20:00:00,492][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T20:01:00,351][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T20:01:00,381][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T20:01:00,411][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T20:01:24,411][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:01:24,411][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:01:24,411][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:01:30,443][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2018-01-07T20:01:30,443][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2018-01-07T20:01:30,443][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2018-01-07T20:01:47,085][INFO ][logstash.pipeline        ] Pipeline terminated {"pipeline.id"=>"main"}
[2018-01-07T20:21:12,698][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"D:/www/sdk/dakaKoa2/logstash-6.1.1/modules/fb_apache/configuration"}
[2018-01-07T20:21:12,778][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"D:/www/sdk/dakaKoa2/logstash-6.1.1/modules/netflow/configuration"}
[2018-01-07T20:21:13,161][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-01-07T20:21:15,645][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.1.1"}
[2018-01-07T20:21:17,285][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-01-07T20:21:26,768][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//127.0.0.1:9200], index=>"pserson", document_type=>"score", document_id=>"%{id}", id=>"d27b06b398a2ed9e1b77c7e21b9f2a9f12415a52925baecf075c9c6cdc94017c", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_9fb67236-623a-4d2a-a210-2d07142706b9", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-01-07T20:21:40,422][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2018-01-07T20:21:40,462][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T20:21:41,072][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2018-01-07T20:21:41,828][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>nil}
[2018-01-07T20:21:41,868][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-01-07T20:21:41,908][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-01-07T20:21:42,529][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-01-07T20:21:44,893][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1:9200"]}
[2018-01-07T20:21:44,943][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500, :thread=>"#<Thread:0x5fb11f14 run>"}
[2018-01-07T20:21:48,813][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2018-01-07T20:21:49,253][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-01-07T20:21:49,483][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:21:49,763][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2018-01-07T20:25:30,079][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"D:/www/sdk/dakaKoa2/logstash-6.1.1/modules/fb_apache/configuration"}
[2018-01-07T20:25:30,159][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"D:/www/sdk/dakaKoa2/logstash-6.1.1/modules/netflow/configuration"}
[2018-01-07T20:25:30,589][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2018-01-07T20:25:32,111][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.1.1"}
[2018-01-07T20:25:33,403][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-01-07T20:25:40,634][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//127.0.0.1:9200], index=>"pserson", document_type=>"score", document_id=>"%{id}", id=>"d27b06b398a2ed9e1b77c7e21b9f2a9f12415a52925baecf075c9c6cdc94017c", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_4ea40640-63af-4699-b993-957b63eaabc2", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2018-01-07T20:25:41,561][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://127.0.0.1:9200/]}}
[2018-01-07T20:25:41,651][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://127.0.0.1:9200/, :path=>"/"}
[2018-01-07T20:25:41,981][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://127.0.0.1:9200/"}
[2018-01-07T20:25:42,131][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>nil}
[2018-01-07T20:25:42,171][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2018-01-07T20:25:42,241][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-01-07T20:25:42,321][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-01-07T20:25:42,421][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//127.0.0.1:9200"]}
[2018-01-07T20:25:42,511][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500, :thread=>"#<Thread:0x3be6bfe8 run>"}
[2018-01-07T20:25:42,871][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
[2018-01-07T20:25:43,083][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2018-01-07T20:26:06,920][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T20:26:07,200][INFO ][logstash.inputs.jdbc     ] (0.040000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T20:26:07,310][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T20:27:03,111][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT version()
[2018-01-07T20:27:03,358][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT count(*) AS `count` FROM (SELECT * FROM users) AS `t1` LIMIT 1
[2018-01-07T20:27:03,408][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:27:03,408][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:27:03,508][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:27:03,508][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:27:03,508][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:27:03,508][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:27:03,508][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:27:03,708][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:27:03,578][WARN ][logstash.runner          ] SIGINT received. Shutting down the agent.
[2018-01-07T20:27:03,918][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2018-01-07T20:27:03,978][INFO ][logstash.inputs.jdbc     ] (0.000000s) SELECT * FROM (SELECT * FROM users) AS `t1` LIMIT 50000 OFFSET 0
[2018-01-07T20:27:03,968][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
[2018-01-07T20:27:04,440][FATAL][logstash.runner          ] SIGINT received. Terminating immediately..
